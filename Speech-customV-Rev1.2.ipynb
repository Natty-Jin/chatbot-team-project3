{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/23/2024 05:18:01 PM 대한민국 표준시] Batch avatar synthesis job submitted successfully\n",
      "[10/23/2024 05:18:01 PM 대한민국 표준시] Job ID: 26e2a9ee-f3ef-4182-8be3-ade932f6f048\n",
      "[10/23/2024 05:18:01 PM 대한민국 표준시] batch avatar synthesis job is still running, status [NotStarted]\n",
      "[10/23/2024 05:18:07 PM 대한민국 표준시] Batch synthesis job succeeded, download URL: https://stttssvcprodusw2.blob.core.windows.net/batchsynthesis-output/7ac1ed4474194a33be18699537ba74f7/26e2a9ee-f3ef-4182-8be3-ade932f6f048/0001.mp4?skoid=fdd04a02-98a3-46a7-830a-91140970cca0&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skt=2024-10-23T00%3A09%3A27Z&ske=2024-10-29T00%3A14%3A27Z&sks=b&skv=2023-11-03&sv=2023-11-03&st=2024-10-23T08%3A13%3A06Z&se=2024-10-26T08%3A18%3A06Z&sr=b&sp=rl&sig=9uGj5aGFuNpyd8bqmLJAZIM6OkunTB0%2BGA%2BkhfJe%2BLQ%3D\n",
      "[10/23/2024 05:18:07 PM 대한민국 표준시] batch avatar synthesis job succeeded\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import requests\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,  # set to logging.DEBUG for verbose output\n",
    "        format=\"[%(asctime)s] %(message)s\", datefmt=\"%m/%d/%Y %I:%M:%S %p %Z\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# The endpoint (and key) could be gotten from the Keys and Endpoint page in the Speech service resource.\n",
    "# The endpoint would be like: https://<region>.api.cognitive.microsoft.com or https://<custom_domain>.cognitiveservices.azure.com\n",
    "# If you want to use passwordless authentication, custom domain is required.\n",
    "SPEECH_ENDPOINT = os.getenv('SPEECH_ENDPOINT',\"https://westus2.api.cognitive.microsoft.com\")\n",
    "# We recommend to use passwordless authentication with Azure Identity here; meanwhile, you can also use a subscription key instead\n",
    "PASSWORDLESS_AUTHENTICATION = False\n",
    "API_VERSION = \"2024-04-15-preview\"\n",
    "\n",
    "\n",
    "def _create_job_id():\n",
    "    # the job ID must be unique in current speech resource\n",
    "    # you can use a GUID or a self-increasing number\n",
    "    return uuid.uuid4()\n",
    "\n",
    "\n",
    "def _authenticate():\n",
    "    if PASSWORDLESS_AUTHENTICATION:\n",
    "        # Refer to https://learn.microsoft.com/python/api/overview/azure/identity-readme?view=azure-python#defaultazurecredential\n",
    "        # for more information about Azure Identity\n",
    "        # For example, your app can authenticate using your Azure CLI sign-in credentials with when developing locally.\n",
    "        # Your app can then use a managed identity once it has been deployed to Azure. No code changes are required for this transition.\n",
    "\n",
    "        # When developing locally, make sure that the user account that is accessing batch avatar synthesis has the right permission.\n",
    "        # You'll need Cognitive Services User or Cognitive Services Speech User role to submit batch avatar synthesis jobs.\n",
    "        credential = DefaultAzureCredential()\n",
    "        token = credential.get_token('https://cognitiveservices.azure.com/.default')\n",
    "        return {'Authorization': f'Bearer {token.token}'}\n",
    "    else:\n",
    "        SUBSCRIPTION_KEY = os.getenv(\"SUBSCRIPTION_KEY\", '1ff2d7a7379b4e349aa1734718de89fc')\n",
    "        return {'Ocp-Apim-Subscription-Key': SUBSCRIPTION_KEY}\n",
    "\n",
    "\n",
    "def submit_synthesis(job_id: str):\n",
    "    url = f'{SPEECH_ENDPOINT}/avatar/batchsyntheses/{job_id}?api-version={API_VERSION}'\n",
    "    header = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    header.update(_authenticate())\n",
    "    isCustomized = False\n",
    "\n",
    "    payload = {\n",
    "        'synthesisConfig': {\n",
    "            \"voice\": 'en-US-JennyMultilingualNeural',\n",
    "        },\n",
    "        # Replace with your custom voice name and deployment ID if you want to use custom voice.\n",
    "        # Multiple voices are supported, the mixture of custom voices and platform voices is allowed.\n",
    "        # Invalid voice name or deployment ID will be rejected.\n",
    "        'customVoices': {\n",
    "            # \"YOUR_CUSTOM_VOICE_NAME\": \"YOUR_CUSTOM_VOICE_ID\"\n",
    "        },\n",
    "        \"inputKind\": \"plainText\",\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"content\": \"Hi, I'm a virtual assistant created by Microsoft.\",\n",
    "            },\n",
    "        ],\n",
    "        \"avatarConfig\":\n",
    "        {\n",
    "            \"customized\": isCustomized, # set to True if you want to use customized avatar\n",
    "            \"talkingAvatarCharacter\": 'Lisa-casual-sitting',  # talking avatar character\n",
    "            \"videoFormat\": \"mp4\",  # mp4 or webm, webm is required for transparent background\n",
    "            \"videoCodec\": \"h264\",  # hevc, h264 or vp9, vp9 is required for transparent background; default is hevc\n",
    "            \"subtitleType\": \"soft_embedded\",\n",
    "            \"backgroundColor\": \"#FFFFFFFF\", # background color in RGBA format, default is white; can be set to 'transparent' for transparent background\n",
    "            # \"backgroundImage\": \"https://samples-files.com/samples/Images/jpg/1920-1080-sample.jpg\", # background image URL, only support https, either backgroundImage or backgroundColor can be set\n",
    "        }\n",
    "        if isCustomized\n",
    "        else \n",
    "        {\n",
    "        \"customized\": isCustomized, # set to True if you want to use customized avatar\n",
    "        \"talkingAvatarCharacter\": 'Lisa',  # talking avatar character\n",
    "        \"talkingAvatarStyle\": 'casual-sitting',  # talking avatar style, required for prebuilt avatar, optional for custom avatar\n",
    "        \"videoFormat\": \"mp4\",  # mp4 or webm, webm is required for transparent background\n",
    "        \"videoCodec\": \"h264\",  # hevc, h264 or vp9, vp9 is required for transparent background; default is hevc\n",
    "        \"subtitleType\": \"soft_embedded\",\n",
    "        \"backgroundColor\": \"#FFFFFFFF\", # background color in RGBA format, default is white; can be set to 'transparent' for transparent background\n",
    "        # \"backgroundImage\": \"https://samples-files.com/samples/Images/jpg/1920-1080-sample.jpg\", # background image URL, only support https, either backgroundImage or backgroundColor can be set\n",
    "    }  \n",
    "    }\n",
    "\n",
    "    response = requests.put(url, json.dumps(payload), headers=header)\n",
    "    if response.status_code < 400:\n",
    "        logger.info('Batch avatar synthesis job submitted successfully')\n",
    "        logger.info(f'Job ID: {response.json()[\"id\"]}')\n",
    "        return True\n",
    "    else:\n",
    "        logger.error(f'Failed to submit batch avatar synthesis job: [{response.status_code}], {response.text}')\n",
    "\n",
    "\n",
    "def get_synthesis(job_id):\n",
    "    url = f'{SPEECH_ENDPOINT}/avatar/batchsyntheses/{job_id}?api-version={API_VERSION}'\n",
    "    header = _authenticate()\n",
    "\n",
    "    response = requests.get(url, headers=header)\n",
    "    if response.status_code < 400:\n",
    "        logger.debug('Get batch synthesis job successfully')\n",
    "        logger.debug(response.json())\n",
    "        if response.json()['status'] == 'Succeeded':\n",
    "            logger.info(f'Batch synthesis job succeeded, download URL: {response.json()[\"outputs\"][\"result\"]}')\n",
    "        return response.json()['status']\n",
    "    else:\n",
    "        logger.error(f'Failed to get batch synthesis job: {response.text}')\n",
    "\n",
    "\n",
    "def list_synthesis_jobs(skip: int = 0, max_page_size: int = 100):\n",
    "    \"\"\"List all batch synthesis jobs in the subscription\"\"\"\n",
    "    url = f'{SPEECH_ENDPOINT}/avatar/batchsyntheses?api-version={API_VERSION}&skip={skip}&maxpagesize={max_page_size}'\n",
    "    header = _authenticate()\n",
    "\n",
    "    response = requests.get(url, headers=header)\n",
    "    if response.status_code < 400:\n",
    "        logger.info(f'List batch synthesis jobs successfully, got {len(response.json()[\"values\"])} jobs')\n",
    "        logger.info(response.json())\n",
    "    else:\n",
    "        logger.error(f'Failed to list batch synthesis jobs: {response.text}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    job_id = _create_job_id()\n",
    "    if submit_synthesis(job_id):\n",
    "        while True:\n",
    "            status = get_synthesis(job_id)\n",
    "            if status == 'Succeeded':\n",
    "                logger.info('batch avatar synthesis job succeeded')\n",
    "                break\n",
    "            elif status == 'Failed':\n",
    "                logger.error('batch avatar synthesis job failed')\n",
    "                break\n",
    "            else:\n",
    "                logger.info(f'batch avatar synthesis job is still running, status [{status}]')\n",
    "                time.sleep(5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
