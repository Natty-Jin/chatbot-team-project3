{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import PyPDF2\n",
    "import gradio as gr\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "# Azure OpenAI 설정\n",
    "endpoint = \"https://eueastproject3-team2.openai.azure.com/\"\n",
    "deployment = \"project3-team2-gpt-4o\"\n",
    "subscription_key = \"a83ed49c38b54298bb690a721a87599b\"  # API 키\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일에서 내용을 읽어오는 함수들\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def read_docx_file(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def read_pdf_file(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        return \"\\n\".join([page.extract_text() for page in reader.pages])\n",
    "\n",
    "def read_file(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == '.txt':\n",
    "        return read_txt_file(file_path)\n",
    "    elif ext == '.docx':\n",
    "        return read_docx_file(file_path)\n",
    "    elif ext == '.pdf':\n",
    "        return read_pdf_file(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "Running on public URL: https://077fc2b7d24b003c07.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://077fc2b7d24b003c07.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Local\\Temp\\ipykernel_13492\\733959072.py\", line 77, in ask_hanseoyun\n",
      "    completion = client.chat.completions.create(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\resources\\chat\\completions.py\", line 668, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py\", line 936, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py\", line 1040, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'low'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Local\\Temp\\ipykernel_13492\\733959072.py\", line 77, in ask_hanseoyun\n",
      "    completion = client.chat.completions.create(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\resources\\chat\\completions.py\", line 668, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py\", line 936, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kbg_0\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py\", line 1040, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'low'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "import PyPDF2\n",
    "import gradio as gr\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "# 파일에서 내용을 읽어오는 함수들\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def read_docx_file(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def read_pdf_file(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        return \"\\n\".join([page.extract_text() for page in reader.pages])\n",
    "\n",
    "def read_file(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == '.txt':\n",
    "        return read_txt_file(file_path)\n",
    "    elif ext == '.docx':\n",
    "        return read_docx_file(file_path)\n",
    "    elif ext == '.pdf':\n",
    "        return read_pdf_file(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "\n",
    "# 그라운딩 데이터 폴더에서 모든 파일을 읽어와서 시스템 메시지에 추가\n",
    "def load_grounding_data(folder_path):\n",
    "    grounding_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.txt', '.docx', '.pdf')):\n",
    "                grounding_files.append(os.path.join(root, file))\n",
    "\n",
    "    system_message = \"\"\n",
    "    for file_path in grounding_files:\n",
    "        try:\n",
    "            file_content = read_file(file_path)\n",
    "            system_message += f\"\\n\\n{file_content}\"\n",
    "            print(f\"Successfully added content from {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {file_path}: {e}\")\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "# 그라운딩 데이터 폴더 경로 설정\n",
    "grounding_data_folder = 'grounding-data'  # 폴더 경로를 지정하세요.\n",
    "\n",
    "# Azure OpenAI 설정\n",
    "endpoint = \"https://eueastproject3-team2.openai.azure.com/\"\n",
    "deployment = \"project3-team2-gpt-4o\"\n",
    "subscription_key = \"a83ed49c38b54298bb690a721a87599b\"  # API 키\n",
    "\n",
    "# Initialize Azure OpenAI client with key-based authentication\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "\n",
    "# GPT 호출 함수\n",
    "def ask_hanseoyun(prompt, history):\n",
    "    # 그라운딩 데이터를 시스템 메시지에 포함\n",
    "    grounding_message = load_grounding_data(grounding_data_folder)\n",
    "    system_message = f\"너는 버츄얼 아이돌인데, 여러명의 자아를 가지고 있으니 grounding_message에 있는 데이터를 토대로 user prompt에서 user가 원하는 페르소나가 나올 때 그 인격체의 페르소나를 사용해서 대답해줘, **예시** 서윤아 너의 체형은 어떻게 돼?, 민혁아 너의 체형은 어떻게 돼?, 재민아 너의 체형은 어떻게 돼? 라는 말에 각 페르소나 txt 파일을 참고하여 이름에 맞는 페르소나의 각 내용을 답변 해주면 돼. **추가** 답변은 user가 다른 페르소나의 이름을 불렀을 때를 제외하고 마지막으로 불렀던 페르소나의 정보를 기준으로 답변을 이어가면 돼 **예시** 민혁아 너의 체중은 어떻게 돼?. 너의 키는?이라는 말에 이전 대화가 민혁이의 페르소나에서 멈췄기 때문에 민혁이의 페르소나를 이어 가면 됨. 마지막 대화 페르소나가 재민이면 재민이의 페르소나를 말하고, 마지막 대화 페르소나가 서윤이면 서윤이의 페르소나 정보를 말해\\n{grounding_message}\"\n",
    "\n",
    "    # GPT와의 대화 설정\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},  # 그라운딩 데이터 포함\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=4000,\n",
    "        temperature=0.3,\n",
    "        top_p=0.75,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    # ChatCompletion 객체를 딕셔너리로 변환하고 content 값 추출\n",
    "    completion_dict = completion.to_dict()\n",
    "    content_value = completion_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # history에 사용자의 질문과 AI의 응답을 추가\n",
    "    history.append((prompt, content_value))\n",
    "\n",
    "    # history와 빈 입력 필드를 반환\n",
    "    return history, \"\"\n",
    "\n",
    "\n",
    "# Gradio 인터페이스 설정\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 2조의 버츄얼 아이돌과 대화\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot()  # 대화형 UI 생성\n",
    "            with gr.Column():\n",
    "                prompt = gr.Textbox(\n",
    "                    label=\"질문을 입력하세요\",\n",
    "                    placeholder=\"프롬프트를 입력하세요\",\n",
    "                    scale=5,\n",
    "                )\n",
    "                send_button = gr.Button(\"전송\", scale=1)\n",
    "                clear_button = gr.Button(\"대화창 지우기\", scale=1)\n",
    "\n",
    "            # 전송 버튼을 submit 방식으로 연결\n",
    "            prompt.submit(\n",
    "                fn=ask_hanseoyun, inputs=[prompt, chatbot], outputs=[chatbot, prompt]\n",
    "            )\n",
    "\n",
    "            # 전송 버튼 클릭 시에도 동일한 함수 호출\n",
    "            send_button.click(\n",
    "                fn=ask_hanseoyun, inputs=[prompt, chatbot], outputs=[chatbot, prompt]\n",
    "            )\n",
    "\n",
    "            # 대화창 지우기 버튼 클릭 시 대화 기록을 지우는 기능\n",
    "            clear_button.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Running on local URL:  http://127.0.0.1:7865\n",
      "Running on public URL: https://2b0ec5e38615b03a25.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2b0ec5e38615b03a25.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n",
      "Successfully added content from grounding-data\\강민혁.txt\n",
      "Successfully added content from grounding-data\\이재민.txt\n",
      "Successfully added content from grounding-data\\한서윤.txt\n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "import PyPDF2\n",
    "import gradio as gr\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "# 파일에서 내용을 읽어오는 함수들\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def read_docx_file(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def read_pdf_file(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        return \"\\n\".join([page.extract_text() for page in reader.pages])\n",
    "\n",
    "def read_file(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == '.txt':\n",
    "        return read_txt_file(file_path)\n",
    "    elif ext == '.docx':\n",
    "        return read_docx_file(file_path)\n",
    "    elif ext == '.pdf':\n",
    "        return read_pdf_file(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "\n",
    "# 그라운딩 데이터 폴더에서 모든 파일을 읽어와서 시스템 메시지에 추가\n",
    "def load_grounding_data(folder_path):\n",
    "    grounding_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.txt', '.docx', '.pdf')):\n",
    "                grounding_files.append(os.path.join(root, file))\n",
    "\n",
    "    grounding_data = {}\n",
    "    for file_path in grounding_files:\n",
    "        try:\n",
    "            file_content = read_file(file_path)\n",
    "            persona_name = os.path.splitext(os.path.basename(file_path))[0]  # 파일 이름을 페르소나 이름으로 사용\n",
    "            grounding_data[persona_name] = file_content\n",
    "            print(f\"Successfully added content from {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {file_path}: {e}\")\n",
    "\n",
    "    return grounding_data\n",
    "\n",
    "\n",
    "# 그라운딩 데이터 폴더 경로 설정\n",
    "grounding_data_folder = 'grounding-data'  # 폴더 경로를 지정하세요.\n",
    "\n",
    "# Azure OpenAI 설정\n",
    "endpoint = \"https://eueastproject3-team2.openai.azure.com/\"\n",
    "deployment = \"project3-team2-gpt-4o\"\n",
    "subscription_key = \"a83ed49c38b54298bb690a721a87599b\"  # API 키\n",
    "\n",
    "# Initialize Azure OpenAI client with key-based authentication\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# GPT 호출 함수\n",
    "def ask_hanseoyun(prompt, persona, history):\n",
    "    # 그라운딩 데이터를 시스템 메시지에 포함\n",
    "    grounding_data = load_grounding_data(grounding_data_folder)\n",
    "\n",
    "    if persona in grounding_data:\n",
    "        persona_data = grounding_data[persona]\n",
    "        system_message = f\"너는 {persona}라는 페르소나야. 이 페르소나의 정보는 다음과 같아:\\n\\n{persona_data}\\n\\n\" \\\n",
    "                         f\"**추가**: 마지막 대화의 페르소나가 {persona}였기 때문에 이후 질문도 이 페르소나를 기준으로 대답해줘.\"\n",
    "    else:\n",
    "        system_message = f\"페르소나 정보가 없어. 현재 선택된 페르소나는 {persona}이지만, 해당 정보는 불러올 수 없어.\"\n",
    "\n",
    "    # GPT와의 대화 설정\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},  # 선택된 페르소나의 데이터 포함\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=4000,\n",
    "        temperature=0.3,\n",
    "        top_p=0.75,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None, \n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    # ChatCompletion 객체를 딕셔너리로 변환하고 content 값 추출\n",
    "    completion_dict = completion.to_dict()\n",
    "    content_value = completion_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # history에 사용자의 질문과 AI의 응답을 추가\n",
    "    history.append((prompt, content_value))\n",
    "\n",
    "    # history와 빈 입력 필드를 반환\n",
    "    return history, \"\"\n",
    "\n",
    "\n",
    "# Gradio 인터페이스 설정\n",
    "def get_available_personas():\n",
    "    # 폴더에서 사용할 수 있는 페르소나 이름 목록을 추출\n",
    "    grounding_data = load_grounding_data(grounding_data_folder)\n",
    "    return list(grounding_data.keys())\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 2조의 버츄얼 아이돌과 대화\")\n",
    "\n",
    "    available_personas = get_available_personas()  # 페르소나 리스트\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            persona_dropdown = gr.Dropdown(label=\"페르소나를 선택하세요\", choices=available_personas, value=available_personas[0])\n",
    "            chatbot = gr.Chatbot()  # 대화형 UI 생성\n",
    "            with gr.Column():\n",
    "                prompt = gr.Textbox(\n",
    "                    label=\"질문을 입력하세요\",\n",
    "                    placeholder=\"프롬프트를 입력하세요\",\n",
    "                    scale=5,\n",
    "                )\n",
    "                send_button = gr.Button(\"전송\", scale=1)\n",
    "                clear_button = gr.Button(\"대화창 지우기\", scale=1)\n",
    "\n",
    "            # 전송 버튼을 submit 방식으로 연결\n",
    "            prompt.submit(\n",
    "                fn=ask_hanseoyun, inputs=[prompt, persona_dropdown, chatbot], outputs=[chatbot, prompt]\n",
    "            )\n",
    "\n",
    "            # 전송 버튼 클릭 시에도 동일한 함수 호출\n",
    "            send_button.click(\n",
    "                fn=ask_hanseoyun, inputs=[prompt, persona_dropdown, chatbot], outputs=[chatbot, prompt]\n",
    "            )\n",
    "\n",
    "            # 대화창 지우기 버튼 클릭 시 대화 기록을 지우는 기능\n",
    "            clear_button.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "    demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
